#!/usr/bin/env perl

package RUM::Script::Pipeline;

use strict;
use warnings;
use FindBin qw($Bin);
use lib "$Bin/../lib";
use RUM::Script;

RUM::Script->run_with_logging("RUM::Script::Runner");

=pod

=head1 NAME

RUM_runner

=head1 SYNOPSIS

  RUM_runner.pl [OPTIONS] --config <config_file> -o <output_dir> --name <name> READS
  RUM_runner.pl [OPTIONS] --config <config_file> -o <output_dir> --name <name> FORWARD REVERSE
  RUM_runner.pl --help
  RUM_runner.pl --version
  RUM_runner.pl --kill
  RUM_runner.pl --status 

=head1 DESCRIPTION

  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  RUM version: $version
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                   _   _   _   _   _   _
                 // \\// \\// \\// \\// \\// \\/
                //\\_//\\_//\\_//\\_//\\_//\\_//
          o_O__O_ o
         | ====== |       .-----------.
         `--------'       |||||||||||||
          || ~~ ||        |-----------|
          || ~~ ||        | .-------. |
          ||----||        ! | UPENN | !
         //      \\        \`-------'/
        // /!  !\ \\        \_  O  _/
       !!__________!!         \   /
       ||  ~~~~~~  ||          `-'
       || _        ||
       |||_|| ||\/|||
       ||| \|_||  |||
       ||          ||
       ||  ~~~~~~  ||
       ||__________||
  .----|||        |||------------------.
       ||\\      //||                 /|
       |============|                //
       `------------'               //
  ---------------------------------'/
  ---------------------------------'
    .------------------------------------.
    | RNA-Seq Unified Mapper (RUM) Usage |
    ` ================================== '

=head1 OPTIONS

There are many options, but RUM is typically run with the
defaults. The option -kill is also quite useful to stop a run, because
killing just the main program will not always kill the spawned
processes.

=head2 Common Options

=over 4

=item B<READ_FILES>

For unpaired data, the single file of reads.  For paired data the
files of forward and reverse reads.

NOTE ON FILE FORMATS: Files can be either fasta or fastq, the type is
inferred.

=item B<--config> I<config_file>

This file tells RUM where to find the various executables and indexes.
This file is included in the 'lib' directory when you download an
organism, for example rum.config_mm9 for mouse build mm9, which will
work if you leave everything in its default location.  To modify or
make your own config file, run this program with the single argument
'config' for more information on the config file.

=item B<-o>, B<--output-dir> I<output_dir>

Where to write the temp, interemediate, and results files.

=item B<--chunks> I<num_chunks>

The number of pieces to break the job into.  Use one chunk unless you
are on a cluster, or have multiple cores with lots of RAM.  Have at
least one processing core per chunk.  A genome like human will also
need about 5 to 6 Gb of RAM per chunk.  Even with a small genome, if
you have tens of millions of reads, you will still need a few Gb of
RAM to get through the post-processing.

=item B<--name> I<name>

A string to identify this run - use only alphanumeric, underscores,
and dashes.  No whitespace or other characters.  Must be less than 250
characters.

=back

=head2 Less Common Options

=over 4

=item B<--strand-specific>

If the data are strand specific, then you can use this option to
generate strand specific coverage plots and quantified values.

=item B<--dna>

Run in dna mode, meaning don't map across splice junctions.

=item B<--genome-only>

Do RNA mapping, but without using a transcript database.  Note: there
will be no feature quantifications in this mode, because those are
based on the transcript database.

=item B<--variable-read-lengths>

Set this if your reads are not all of the same length.

=item B<--limit-nu> I<n>

Limits the number of ambiguous mappers in the final output by removing
all reads that map to n locations or more.

=item B<--limit-bowtie-nu>

Limits the number of ambiguous mappers in the Bowtie run to a max of
100.  If you have short reads and a large genome, or a very repetitive
genome, this might be necessary to keep the bowtie files from getting
out of hand - 10Gb per lane is not abnormal but 100Gb might be. (note:
45 bases is considered short for mouse, 70 bases considered long,
between it's hard to say).

=item B<--quantify>

Use this *if* using the -dna flag and you still want quantified
features.  If this is set you *must* have the gene models file
specified in the rum config file.  Without the -dna flag quantified
features are generated by default so you don't need to set this.

=item B<--junctions>

Use this *if* using the -dna flag and you still want junction
calls. If this is set you should have the gene models file specified
in the rum config file (if you have one).  Without the -dna flag
junctions generated by default so you don't need to set this.

=item B<--min-length> I<x>

Don't report alignments less than this long.  The default = 50 if the
readlength >= 80, else = 35 if readlength >= 45 else = 0.8 *
readlength.  Don't set this too low you will start to pick up a lot of
garbage.

=item B<--count-mismatches>

Report in the last column the number of mismatches, ignoring
insertions

=item B<--alt-genes> I<x>

x is a file with gene models to use for calling junctions novel.  If
not specified will use the gene models file specified in the config
file.

=item B<--alt-quant> I<x>

If specified x will be used to quantify features in addition to the
gene models file specified in the config file.  Both are reported to
separate files.

=item B<--qsub>

Use qsub to fire the job off to multiple nodes on a cluster.  This
means you're on a cluster that understands qsub like the Sun Grid
Engine.

Note: without using -qsub, you can still specify more than one chunk.
It should fire each chunk off to a separate core.  But don't use more
chunks than you have cores, because that can slow things down
considerably.

=item B<--max-insertions-per-read> I<n>

Allow at most n insertions in one read.  The default is n=1.  Setting
n>1 is only allowed for single end reads.  Don't raise it unless you
know what you are doing, because it can greatly increase the false
alignments.

=item B<--no-clean>

Do not remove the intermediate and temp files after finishing.

=item B<--preserve-names>

Keep the original read names in the SAM output file.  Note: this
doesn't work when there are variable length reads.

=item B<--ram> I<n>

On some systems RUM might not be able to determine the amount of RAM
you have.  In that case, with this option you can specify the number
of Gb of ram you want to dedicate to each chunk.  This is rarely
necessary and never necessary if you have at least 6 Gb per chunk.

=back

=head2 Commands

=over 4

=item B<--kill>

To kill a job, run with all the same parameters but add -kill.  Note:
it is not sufficient to just terminate RUM_runner.pl, that will leave
other phantom processes.  Use -kill instead.

=item B<-V>, B<--version>

Returns the current version.

=back

=head2 BLAT options

You can tweak the BLAT portion of RUM to suit your needs. We found the
following to be a good balance for speed, sensitivity, and temporary
file size.

=over 4

=item B<--minIdentity> I<x>

Run blat with minIdentity=x (default x=93). You shouldn't need to
change this.

=item B<--tileSize> I<x>

Run blat with tileSize=x (default x=12). You shouldn't need to change
this.

=item B<--stepSize> I<x>

Run blat with stepSize=x (default x=6).  You shouldn't need to change
this.

=item B<--repMatch> I<x>

Run blat with repMatch=x (default x=256).  You shouldn't need to
change this.

=item B<--maxIntron> I<x>

Run blat with maxIntron=x (default x=50000).  You shouldn't need to
change this.



Default config files are supplied with each organism.  If you need to
make or modify one then running RUM_runner.pl with the one argument
'config' gives an explaination of the the file.

This program writes very large intermediate files.  If you have a
large genome such as mouse or human then it is recommended to run in
chunks on a cluster, or a machine with multiple processors.  Running
with under five million reads per chunk is usually best, and getting
it under a million reads per chunk will speed things considerably.

You can put an 's' after the number of chunks if they have already
been broken into chunks, so as to avoid repeating this time-consuming
step.

=cut
